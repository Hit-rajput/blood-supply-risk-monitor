{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9565ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7b824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab34bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorontoCollisionsExtractor:\n",
    "    \"\"\"Extract Toronto Police traffic collision data via ArcGIS REST API.\"\"\"\n",
    "\n",
    "    BASE_URL = \"https://services.arcgis.com/S9th0jAJ7bqgIRjw/arcgis/rest/services/Traffic_Collisions_Open_Data/FeatureServer/0/query\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bronze_path = Path(\"data/bronze/toronto_collisions\")\n",
    "        self.bronze_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def fetch_collisions(self, start_year: int = 2014, end_year: int = None) -> pd.DataFrame:\n",
    "       \n",
    "        if end_year is None:\n",
    "            end_year = datetime.now().year\n",
    "\n",
    "        \n",
    "        logger.info(f\"Fetching Toronto collision data: {start_year}-{end_year}\")\n",
    "\n",
    "        all_records = []\n",
    "\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            logger.info(f\"  Fetching year {year}...\")\n",
    "            offset = 0\n",
    "            year_records = []\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                params = {\n",
    "                    'where': f\"OCC_YEAR = '{year}'\",\n",
    "                    'outFields': '*',\n",
    "                    'returnGeometry': 'false',\n",
    "                    'f': 'json',\n",
    "                    'resultRecordCount': 2000,\n",
    "                    'resultOffset': offset\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(self.BASE_URL, params=params, timeout=30)\n",
    "                    \n",
    "             \n",
    "                    if response.status_code == 400:\n",
    "                        logger.error(f\" API Rejected URL: {self.BASE_URL}\")\n",
    "                        logger.error(\"Please verify the Service URL on the Toronto Police Open Data Portal.\")\n",
    "                        return pd.DataFrame(all_records)\n",
    "                        \n",
    "                    response.raise_for_status()\n",
    "                    data = response.json()\n",
    "\n",
    "                    if 'features' not in data or not data['features']:\n",
    "                        break\n",
    "\n",
    "                    records = [feature['attributes'] for feature in data['features']]\n",
    "                    year_records.extend(records)\n",
    "\n",
    "                    if len(records) < 2000:\n",
    "                        break\n",
    "\n",
    "                    offset += 2000\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"    Error fetching year {year}: {e}\")\n",
    "                    break\n",
    "\n",
    "            logger.info(f\"   Year {year}: {len(year_records):,} total records\")\n",
    "            all_records.extend(year_records)\n",
    "\n",
    "        df = pd.DataFrame(all_records)\n",
    "        if not df.empty:\n",
    "            logger.info(f\"\\n Total records fetched: {len(df):,}\")\n",
    "        return df\n",
    "\n",
    "    def save_raw_data(self, df: pd.DataFrame):\n",
    "        if df.empty:\n",
    "            logger.warning(\"DataFrame is empty. Skipping save.\")\n",
    "            return\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = self.bronze_path / f\"toronto_collisions_{timestamp}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        logger.info(f\"Raw data saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65a2e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-31 17:56:09,352 - __main__ - INFO - Fetching Toronto collision data: 2014-2026\n",
      "2026-01-31 17:56:09,353 - __main__ - INFO -   Fetching year 2014...\n",
      "2026-01-31 17:56:53,863 - __main__ - INFO -    Year 2014: 64,596 total records\n",
      "2026-01-31 17:56:53,867 - __main__ - INFO -   Fetching year 2015...\n",
      "2026-01-31 17:57:34,082 - __main__ - INFO -    Year 2015: 67,265 total records\n",
      "2026-01-31 17:57:34,084 - __main__ - INFO -   Fetching year 2016...\n",
      "2026-01-31 17:58:32,094 - __main__ - INFO -    Year 2016: 69,669 total records\n",
      "2026-01-31 17:58:32,095 - __main__ - INFO -   Fetching year 2017...\n",
      "2026-01-31 17:59:18,642 - __main__ - INFO -    Year 2017: 74,209 total records\n",
      "2026-01-31 17:59:18,675 - __main__ - INFO -   Fetching year 2018...\n",
      "2026-01-31 18:00:06,721 - __main__ - INFO -    Year 2018: 79,271 total records\n",
      "2026-01-31 18:00:06,722 - __main__ - INFO -   Fetching year 2019...\n",
      "2026-01-31 18:00:59,679 - __main__ - INFO -    Year 2019: 82,831 total records\n",
      "2026-01-31 18:00:59,682 - __main__ - INFO -   Fetching year 2020...\n",
      "2026-01-31 18:01:28,485 - __main__ - INFO -    Year 2020: 44,738 total records\n",
      "2026-01-31 18:01:28,486 - __main__ - INFO -   Fetching year 2021...\n",
      "2026-01-31 18:01:55,477 - __main__ - INFO -    Year 2021: 43,745 total records\n",
      "2026-01-31 18:01:55,478 - __main__ - INFO -   Fetching year 2022...\n",
      "2026-01-31 18:02:35,099 - __main__ - INFO -    Year 2022: 59,173 total records\n",
      "2026-01-31 18:02:35,102 - __main__ - INFO -   Fetching year 2023...\n",
      "2026-01-31 18:03:19,308 - __main__ - INFO -    Year 2023: 67,542 total records\n",
      "2026-01-31 18:03:19,309 - __main__ - INFO -   Fetching year 2024...\n",
      "2026-01-31 18:04:06,589 - __main__ - INFO -    Year 2024: 70,181 total records\n",
      "2026-01-31 18:04:06,591 - __main__ - INFO -   Fetching year 2025...\n",
      "2026-01-31 18:04:39,971 - __main__ - INFO -    Year 2025: 49,296 total records\n",
      "2026-01-31 18:04:39,973 - __main__ - INFO -   Fetching year 2026...\n",
      "2026-01-31 18:04:40,200 - __main__ - INFO -    Year 2026: 0 total records\n",
      "2026-01-31 18:04:42,064 - __main__ - INFO - \n",
      " Total records fetched: 772,516\n",
      "2026-01-31 18:04:45,654 - __main__ - INFO - Raw data saved to: data/bronze/toronto_collisions/toronto_collisions_20260131_180442.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    extractor = TorontoCollisionsExtractor()\n",
    "    \n",
    "    df = extractor.fetch_collisions(start_year=2014)\n",
    "    extractor.save_raw_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
